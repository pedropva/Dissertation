%%% -*- coding: utf-8 -*-
\newpage

\chapter{Conclusions}
\label{chap:conclusions}

In this work we created a large scale video dataset for sensitive content detection and a multi-modal approach to sensitive content detection in video. 
%Our model uses both audio and visual features. 
It uses pre-trained convolutional neural networks, and applies a early-fusion feature method, which is simpler than the late-fusion approach since we use a single model to classify both features.

We evaluated our models by testing on a test subset and on a popular dataset. We validated our dataset and baseline approach while maintaining a similar performance to the existing methods.

It is important to note that our approach is not focused on mobile platforms, therefore memory and disk space were not major constraints. 

It is worth mentioning that our overall results on the sensitive content detection are not directly comparable to the related works since their definition of violence do not match ours. However, we could compare our approach on the pornography detection task by testing our best performing baseline model on the NPDI 2k-pornography dataset. Our approach yielded and F2-Score of 88.83\%, compared to our related works, Moreira et. al. with
93.53\%~\cite{moreira2019multimodal} and who also aims at pornography and violence detection, and
Wehrmann et. al. with 95.20\% \cite{wehrmann2018adult}, aiming at only pornography.

\section{Currently published papers}
\label{sec:contrib}

By the the time of this writing, three papers about this work have already been published in conferences: \cite{2019NSFWbaseline}, \cite{2020PornDetectionSBIE}, and \cite{shouldisee}. We also have finished the construction of the dataset for sensitive content detection, to be published soon.

\section{Future Work}
\label{sec:future}


% após o fim desse trabalho é claro que ainda muitos locais em nossa abordagem para melhoria, mas somente com uma extraçaõ de features generalista e baselines, já conseguimos alcançar abordagens estado da arte
%imagino que a partir daqui, o sentido do progresso do trabalho é diminuir e simpleificar a extração de features, ao mesmo tempo especializando, ou seja, treinando a extração de features para a prórpia tarefa
Even with generic feature extraction CNNs we archieved almost 90\% on the pornography detection task. 
One future work is to create a late fusion model and evaluate it based on each feature type.
Another possibility is to extend this approach even further, creating new CNNs from scratch to classify the videos based on, audio, visual and motion features. Both training the feature extraction methods from scratch and using a late fusion could help create a model that balances the use of each multimodal feature.
Another possible future work is to add motion information, such as optical flow, to the dataset and our approach.
One could also test if a sequential model can outperform a non-sequential model in specific cases that demand long term memory, such as long videos with very small sensitive scenes.
Finally, one could investigate misclassified videos in the test sets and use explainability techniques to search for insights on what circunstances our approach fails to correctly detect sensitive content.

\section{Acknowledgements}
\label{sec:acks}
This work was supported by the Artificial Intelligence challenge, created by Brazil's National Research Net (RNP) and Microsoft, in 2019.